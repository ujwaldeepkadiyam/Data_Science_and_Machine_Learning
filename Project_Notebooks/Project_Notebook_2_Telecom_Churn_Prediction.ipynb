{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujwaldeepkadiyam/Data_Science_and_Machine_Learning/blob/main/Project_Notebook_2_Telecom_Churn_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # this is used for the plot the graph\n",
        "import seaborn as sns # used for plot interactive graph.\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from pylab import rcParams"
      ],
      "metadata": {
        "id": "6CBhuZ-tG78S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Download"
      ],
      "metadata": {
        "id": "QzirIye9dm4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_download_path='https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/IBM_Telco_Data/IBM_Cognos_Data.csv'\n",
        "churn_data = pd.read_csv(data_download_path)\n",
        "churn_data.head()"
      ],
      "metadata": {
        "id": "O5dVMAOSF3Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_overview(df, message=\"Data Overview\"):\n",
        "    \"\"\"\n",
        "    Generate an overview of the dataset, including key statistics and information.\n",
        "\n",
        "    Parameters:\n",
        "    - df (DataFrame): The input DataFrame to be analyzed.\n",
        "    - message (str): An optional message to be displayed as the title of the overview.\n",
        "\n",
        "    Returns:\n",
        "    None (prints the overview to the console).\n",
        "    \"\"\"\n",
        "    # Display the provided message as the title of the overview\n",
        "    print(f'{message}:\\n')\n",
        "\n",
        "    # Print the number of rows and features in the dataset\n",
        "    print(\"Rows:\", df.shape[0])\n",
        "    print(\"Number of features:\", df.shape[1])\n",
        "\n",
        "    # Print the names of all features in the dataset\n",
        "    print(\"\\nFeatures:\")\n",
        "    print(df.columns.tolist())\n",
        "\n",
        "    # Print the Variable types in the dataset\n",
        "    print(\"\\nVariable Data Types:\", df.info())\n",
        "\n",
        "    # Print the total count of missing values in the dataset\n",
        "    print(\"\\nMissing values:\", df.isnull().sum().values.sum())\n",
        "\n",
        "    # Print the number of unique values for each feature in the dataset\n",
        "    print(\"\\nUnique values:\")\n",
        "    print(df.nunique())\n"
      ],
      "metadata": {
        "id": "ig3vrotYHP-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_overview(churn_data)"
      ],
      "metadata": {
        "id": "bfybzrzdHya8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_data.describe()"
      ],
      "metadata": {
        "id": "E3QSz1Bh9tiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target Variable Analysis"
      ],
      "metadata": {
        "id": "kSsQD3N2InIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "churn_data['Churn'].value_counts(sort = False)"
      ],
      "metadata": {
        "id": "gVCoHKlkFSP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='Churn', data=churn_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B0fRZs4SSMjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Data to plot\n",
        "# churn_labels = churn_data['Churn'].value_counts(sort=True).index\n",
        "# churn_sizes = churn_data['Churn'].value_counts(sort=True)\n",
        "\n",
        "# # Define colors for the pie chart\n",
        "# colors = [\"Green\", \"red\"]\n",
        "\n",
        "# # Define the degree to which the first slice should be exploded\n",
        "# explode = (0.1, 0)\n",
        "\n",
        "# # Set the size of the plot\n",
        "# rcParams['figure.figsize'] = 6, 6\n",
        "\n",
        "# # Plotting the pie chart\n",
        "# plt.pie(churn_sizes, explode=explode, labels=churn_labels, colors=colors,\n",
        "#         autopct='%1.1f%%', shadow=True, startangle=90)\n",
        "\n",
        "# # Set the title of the plot\n",
        "# plt.title('Percentage of Churn in Customers')\n",
        "\n",
        "# # Display the pie chart\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "j-IE9SfVJqm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis of Categorical Variables"
      ],
      "metadata": {
        "id": "WIvBHZyHPTu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def display_frequency_and_bar_chart(df, column_name):\n",
        "    \"\"\"\n",
        "    Display frequency table and bar chart for a specified column in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (DataFrame): The input dataframe.\n",
        "    - column_name (str): The name of the column for analysis.\n",
        "    \"\"\"\n",
        "    # Frequency Table\n",
        "    frequency_table = df[column_name].value_counts()\n",
        "\n",
        "    # Bar Chart\n",
        "    plt.figure(figsize=(6, 3))\n",
        "    df[column_name].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')\n",
        "\n",
        "    # Adding labels and title\n",
        "    plt.title(f'Frequency of {column_name}')\n",
        "    plt.xlabel(column_name)\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    # Displaying the frequency table\n",
        "    print(f'\\nFrequency Table for {column_name}:\\n')\n",
        "    print(frequency_table)\n",
        "\n",
        "    # Display the bar chart\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'churn_data' is your DataFrame\n",
        "columns_to_analyze = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
        "                      'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
        "                      'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
        "                      'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
        "\n",
        "for column in columns_to_analyze:\n",
        "    display_frequency_and_bar_chart(churn_data, column)\n"
      ],
      "metadata": {
        "id": "kX8sVlisOhV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis on Continuous Variables"
      ],
      "metadata": {
        "id": "vfVVC_q7SEMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def display_stats_and_plots(df, variable_names):\n",
        "    \"\"\"\n",
        "    Display percentiles, box plots, and histograms for specified variables in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (DataFrame): The input dataframe.\n",
        "    - variable_names (list): List of variable names to analyze.\n",
        "    \"\"\"\n",
        "    for variable in variable_names:\n",
        "        # Display Percentiles\n",
        "        print(f\"\\nPercentiles for {variable}:\\n\")\n",
        "        print(df[variable].describe(percentiles=[.1, .2, .3, .4, .5, .6,.7,.8,.9,1]))\n",
        "\n",
        "        # Create Subplots for Box Plot and Histogram\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "        # Box Plot\n",
        "        sns.boxplot(y=variable, data=df, ax=axes[0], color='skyblue')\n",
        "        axes[0].set_title(f'Box Plot of {variable}')\n",
        "\n",
        "        # Histogram\n",
        "        sns.histplot(df[variable], bins=30, kde=True, color='skyblue', ax=axes[1])\n",
        "        axes[1].set_title(f'Histogram of {variable}')\n",
        "\n",
        "        # Adjust layout\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Display the plots\n",
        "        plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'churn_data' is your DataFrame\n",
        "variables_to_analyze = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "display_stats_and_plots(churn_data, variables_to_analyze)\n"
      ],
      "metadata": {
        "id": "eStcm-H0NXE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning and Preparing for Analysis"
      ],
      "metadata": {
        "id": "fkKtD4DtZ6r9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "| Feature         | **Nominal Data**                         | **Ordinal Data**                      |\n",
        "|---------------|--------------------------------|--------------------------------|\n",
        "| **Definition**  | Categorical data with no inherent order | Categorical data with a meaningful order |\n",
        "| **Order**       | No order or ranking | Ordered categories |\n",
        "| **Comparison**  | Only equality (e.g., \"Apple\" ≠ \"Banana\") | Can compare (e.g., \"Good\" > \"Average\") |\n",
        "| **Examples**    | Colors (Red, Blue, Green), Gender (Male, Female), Nationality (Indian, American) | Education Level (High School < Bachelor's < Master's), Satisfaction Ratings (Bad < Average < Good) |\n",
        "| **Numerical Meaning** | No numerical meaning | Relative ranking but no fixed difference |\n",
        "| **Encoding Methods** | One-Hot Encoding, Binary Encoding | Label Encoding, Ordinal Encoding |\n",
        "| **Use Case**    | Identifying categories without ranking | Identifying ranked categories without exact intervals |\n"
      ],
      "metadata": {
        "id": "_bZwX4KtfoGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mapping binary categorical variables to numeric values in churn_data"
      ],
      "metadata": {
        "id": "fNfRso-bbTNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping binary categorical variables to numeric values in churn_data\n",
        "\n",
        "# Convert 'Churn' column to binary (1 for 'Yes', 0 for 'No')\n",
        "churn_data['Churn'] = churn_data['Churn'].map(lambda s: 1 if s == 'Yes' else 0)\n",
        "\n",
        "# Convert 'Gender' column to binary (1 for 'Male', 0 for 'Female')\n",
        "churn_data['gender'] = churn_data['gender'].map(lambda s: 1 if s == 'Male' else 0)\n",
        "\n",
        "# Convert 'Partner' column to binary (1 for 'Yes', 0 for 'No')\n",
        "churn_data['Partner'] = churn_data['Partner'].map(lambda s: 1 if s == 'Yes' else 0)\n",
        "\n",
        "# Convert 'Dependents' column to binary (1 for 'Yes', 0 for 'No')\n",
        "churn_data['Dependents'] = churn_data['Dependents'].map(lambda s: 1 if s == 'Yes' else 0)\n",
        "\n",
        "# Convert 'PhoneService' column to binary (1 for 'Yes', 0 for 'No')\n",
        "churn_data['PhoneService'] = churn_data['PhoneService'].map(lambda s: 1 if s == 'Yes' else 0)\n",
        "\n",
        "# Convert 'PaperlessBilling' column to binary (1 for 'Yes', 0 for 'No')\n",
        "churn_data['PaperlessBilling'] = churn_data['PaperlessBilling'].map(lambda s: 1 if s == 'Yes' else 0)\n",
        "\n",
        "# Replace 'No phone service' with 'No' in 'MultipleLines' column\n",
        "churn_data['MultipleLines'].replace('No phone service', 'No', inplace=True)\n",
        "\n",
        "# Convert 'MultipleLines' column to binary (1 for 'Yes', 0 for 'No')\n",
        "churn_data['MultipleLines'] = churn_data['MultipleLines'].map(lambda s: 1 if s == 'Yes' else 0)\n",
        "\n",
        "# Convert 'OnlineSecurity' column to binary (1 for 'Yes', 0 for 'No')\n",
        "churn_data['OnlineSecurity'] = churn_data['OnlineSecurity'].map(lambda s: 1 if s == 'Yes' else 0)\n",
        "\n",
        "# Convert 'OnlineBackup' column to binary (1 for 'Yes', 0 for 'No')\n",
        "churn_data['OnlineBackup'] = churn_data['OnlineBackup'].map(lambda s: 1 if s == 'Yes' else 0)\n",
        "\n",
        "# Convert 'DeviceProtection' column to binary (1 for 'Yes', 0 for 'No')\n",
        "churn_data['DeviceProtection'] = churn_data['DeviceProtection'].map(lambda s: 1 if s == 'Yes' else 0)\n",
        "\n",
        "# Convert 'TechSupport' column to binary (1 for 'Yes', 0 for 'No')\n",
        "churn_data['TechSupport'] = churn_data['TechSupport'].map(lambda s: 1 if s == 'Yes' else 0)\n",
        "\n",
        "# Convert 'StreamingTV' column to binary (1 for 'Yes', 0 for 'No')\n",
        "churn_data['StreamingTV'] = churn_data['StreamingTV'].map(lambda s: 1 if s == 'Yes' else 0)\n",
        "\n",
        "# Convert 'StreamingMovies' column to binary (1 for 'Yes', 0 for 'No')\n",
        "churn_data['StreamingMovies'] = churn_data['StreamingMovies'].map(lambda s: 1 if s == 'Yes' else 0)\n",
        "\n",
        "#churn_data.info()"
      ],
      "metadata": {
        "id": "U-tY-ftqZ99G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-Hot Encoding of categorical variables"
      ],
      "metadata": {
        "id": "SgldKxztbYBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding for 'InternetService', 'PaymentMethod' and 'Contract' columns in churn_data\n",
        "\n",
        "# Perform one-hot encoding for the 'InternetService' column\n",
        "churn_data = pd.get_dummies(data=churn_data, columns=['InternetService'])\n",
        "\n",
        "\n",
        "# Perform one-hot encoding for the 'PaymentMethod' column\n",
        "churn_data = pd.get_dummies(data=churn_data, columns=['PaymentMethod'])\n",
        "\n",
        "# Perform one-hot encoding for the 'Contract' column\n",
        "churn_data = pd.get_dummies(data=churn_data, columns=['Contract'])\n",
        "\n"
      ],
      "metadata": {
        "id": "tSncxZfDbYR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remaning variables"
      ],
      "metadata": {
        "id": "hgzbyvThj9z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "churn_data[\"MonthlyCharges\"]=churn_data[\"MonthlyCharges\"].astype(int)\n",
        "churn_data[\"TotalCharges\"]=churn_data[\"TotalCharges\"].astype(int)"
      ],
      "metadata": {
        "id": "0f-mcRfnkBLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_data.info()"
      ],
      "metadata": {
        "id": "9nNTMN3IcKGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.ML Model Building:"
      ],
      "metadata": {
        "id": "UZbGpS-5W_cU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test data preparation"
      ],
      "metadata": {
        "id": "ADpQWnEyXDS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features=[col for col in churn_data.columns if col not in ['customerID', 'Churn']]\n",
        "print(features)"
      ],
      "metadata": {
        "id": "0BIbl8GqXChG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Y = churn_data[\"Churn\"].astype(int)\n",
        "X = churn_data[features]\n",
        "\n",
        "# Splitting the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Displaying the shapes of the resulting sets\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of Y_train:\", Y_train.shape)\n",
        "print(\"Shape of Y_test:\", Y_test.shape)\n"
      ],
      "metadata": {
        "id": "MWTC9MxQiTRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree model"
      ],
      "metadata": {
        "id": "dnIjy06cjWql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Instantiate the Decision Tree model\n",
        "decision_tree_model = DecisionTreeClassifier(max_leaf_nodes=20)\n",
        "\n",
        "# Train the model on the training data\n",
        "decision_tree_model.fit(X_train, Y_train)\n",
        "\n",
        "# Predictions on the training set\n",
        "train_predictions = decision_tree_model.predict(X_train)\n",
        "\n",
        "# Predictions on the test set\n",
        "test_predictions = decision_tree_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_accuracy = accuracy_score(Y_train, train_predictions)\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "print(\"\\nClassification Report on Training Data:\")\n",
        "print(classification_report(Y_train, train_predictions))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_accuracy = accuracy_score(Y_test, test_predictions)\n",
        "print(\"\\nTesting Accuracy:\", test_accuracy)\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(Y_test, test_predictions))\n"
      ],
      "metadata": {
        "id": "znp1hWjKjZ3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Result"
      ],
      "metadata": {
        "id": "dItfWGmkyxiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Class Imbalance Impact:**\n",
        "The class imbalance is reflected in the lower performance metrics for the minority class (Churn: Yes).\n",
        "The model is more accurate at predicting instances of the majority class.\n",
        "\n",
        "**Potential Improvements:**\n",
        "\n",
        "Techniques like oversampling (SMOTE) can be explored to address class imbalance and potentially improve performance, especially for the minority class.\n",
        "\n",
        "**Model Limitations:**\n",
        "\n",
        "While the model demonstrates reasonable accuracy, precision, and recall, further improvements and fine-tuning may be explored to enhance its predictive capabilities.\n",
        "\n",
        "**Next Steps:**\n",
        "\n",
        "Consideration of alternative models, such as Random Forest, may be beneficial to evaluate if ensemble methods lead to improved accuracy."
      ],
      "metadata": {
        "id": "mkrxWZqnvyJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Model"
      ],
      "metadata": {
        "id": "sCBVi6BrlCcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Instantiate the Random Forest model\n",
        "random_forest_model = RandomForestClassifier(n_estimators=100, max_features=5, max_depth=8)\n",
        "\n",
        "# Train the model on the training data\n",
        "random_forest_model.fit(X_train, Y_train)\n",
        "\n",
        "# Predictions on the training set\n",
        "train_predictions = random_forest_model.predict(X_train)\n",
        "\n",
        "# Predictions on the test set\n",
        "test_predictions = random_forest_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_accuracy = accuracy_score(Y_train, train_predictions)\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "print(\"\\nClassification Report on Training Data:\")\n",
        "print(classification_report(Y_train, train_predictions))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_accuracy = accuracy_score(Y_test, test_predictions)\n",
        "print(\"\\nTesting Accuracy:\", test_accuracy)\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(Y_test, test_predictions))\n"
      ],
      "metadata": {
        "id": "TwMFjN1ylBvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RF Model Result"
      ],
      "metadata": {
        "id": "ahsPtig9y2rB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Advantages of Random Forest:**\n",
        "\n",
        "Random Forest, with its ensemble nature, demonstrates enhanced predictive performance over the Decision Tree model.\n",
        "Improved accuracy, precision, recall, and F1-score on both training and testing datasets indicate the robustness of the Random Forest approach.\n",
        "\n",
        "**Considerations for Deployment:**\n",
        "\n",
        "Random Forest may be a more suitable model for deployment due to its better performance and ability to handle imbalanced classes.\n",
        "Continued monitoring and potential hyperparameter tuning can further enhance the model's effectiveness.\n",
        "\n",
        "**Final Recommendations:**\n",
        "\n",
        "Given the observed improvements, the Random Forest model is recommended for predicting churn in this scenario.\n",
        "Ongoing evaluation and refinement should be considered for continuous model improvement."
      ],
      "metadata": {
        "id": "czmc10_PwpF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Important features"
      ],
      "metadata": {
        "id": "CZbIxJsBmP-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting feature importances from the trained Random Forest model ('rf')\n",
        "feature_importances = pd.DataFrame(random_forest_model.feature_importances_)\n",
        "\n",
        "# Creating a DataFrame with feature importances and corresponding feature names\n",
        "feature_importances[\"Feature\"] = list(X_train.columns)\n",
        "feature_importances.rename(columns={0: 'Importance'}, inplace=True)\n",
        "\n",
        "# Sorting the DataFrame by feature importance in descending order\n",
        "sorted_feature_importances = feature_importances.sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "# Displaying the top features based on Random Forest feature importances\n",
        "top_features = sorted_feature_importances.head()\n",
        "print(\"Top Features based on Random Forest Feature Importances:\")\n",
        "print(top_features)\n"
      ],
      "metadata": {
        "id": "X5E5RDEPmXYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest model's feature importance analysis reveals critical insights into the factors influencing customer churn prediction. Among the top features, 'tenure' emerges as the most significant determinant, indicating the length of time a customer has been with the telecom service plays a crucial role in predicting churn. Additionally, the contractual agreement type, particularly 'Contract_Month-to-month,' holds substantial importance, suggesting that customers with month-to-month contracts are more likely to churn. 'TotalCharges' and 'MonthlyCharges' also exhibit notable importance, highlighting the financial aspect of customer relationships as a contributing factor. Notably, the presence of 'InternetService_Fiber optic' signifies that the type of internet service subscribed to significantly impacts churn predictions. This feature importance analysis provides actionable insights for telecom companies to strategically address customer retention, focusing on contract types, service duration, and financial considerations to mitigate churn effectively."
      ],
      "metadata": {
        "id": "_7BRKXFJxLvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMOTE to Handle the Class Imbalance"
      ],
      "metadata": {
        "id": "77LbDLNopJNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Instantiate SMOTE\n",
        "smote = SMOTE(random_state=42,sampling_strategy=0.6)\n",
        "\n",
        "# Apply SMOTE to the training data only to avoid data leakage\n",
        "X_train_resampled, Y_train_resampled = smote.fit_resample(X_train, Y_train)\n",
        "\n",
        "# Display the shape before and after SMOTE\n",
        "print(\"Shape of X_train before SMOTE:\", X_train.shape)\n",
        "print(\"Shape of X_train_resampled after SMOTE:\", X_train_resampled.shape)\n",
        "\n",
        "# Now, X_train_resampled and Y_train_resampled can be used for training the model\n",
        "Y_train_resampled.value_counts()"
      ],
      "metadata": {
        "id": "WHCW7HsdpM72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest on Balanced Data"
      ],
      "metadata": {
        "id": "4adCnFVEqgMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Instantiate the Random Forest model\n",
        "random_forest_model = RandomForestClassifier(n_estimators=150, max_features=5, max_depth=7)\n",
        "\n",
        "# Train the model on the training data\n",
        "random_forest_model.fit(X_train_resampled, Y_train_resampled)\n",
        "\n",
        "# Predictions on the training set\n",
        "train_predictions = random_forest_model.predict(X_train_resampled)\n",
        "\n",
        "# Predictions on the test set\n",
        "test_predictions = random_forest_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_accuracy = accuracy_score(Y_train_resampled, train_predictions)\n",
        "print(\"Training Accuracy:\", train_accuracy)\n",
        "print(\"\\nClassification Report on Training Data:\")\n",
        "print(classification_report(Y_train_resampled, train_predictions))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_accuracy = accuracy_score(Y_test, test_predictions)\n",
        "print(\"\\nTesting Accuracy:\", test_accuracy)\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(Y_test, test_predictions))\n"
      ],
      "metadata": {
        "id": "KPofUir-q9Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Impact of SMOTE"
      ],
      "metadata": {
        "id": "KiIWV49-y_Ie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Applying SMOTE has positively influenced the model's ability to predict the minority class, as reflected in the increased recall and F1-score for Churn: Yes in both training and testing datasets.\n",
        "\n",
        "\n",
        "**Balanced Performance:**\n",
        "\n",
        "The model exhibits a more balanced performance across precision and recall for both classes, mitigating the impact of class imbalance observed in the previous Random Forest output.\n",
        "Trade-offs:\n",
        "\n",
        "While there is a slight trade-off in training accuracy, the model's effectiveness in predicting churn instances, especially among customers likely to churn (Churn: Yes), is significantly enhanced.\n",
        "\n",
        "In conclusion, the Random Forest model, after incorporating the SMOTE technique, demonstrates improved sensitivity to predicting customer churn, particularly for the minority class. The trade-off in training accuracy is justifiable, considering the overall enhancement in the model's ability to capture true positives. This refined model, with its balanced performance metrics, holds promise for more accurate and reliable churn predictions. The strategic application of SMOTE proves instrumental in addressing class imbalance, offering a more robust solution for telecom companies aiming to proactively retain customers."
      ],
      "metadata": {
        "id": "bqUEdbIxx9-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Data Analysis Results:"
      ],
      "metadata": {
        "id": "-Mwc6kw9XD7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Analysis Results Compilation:\n",
        "\n",
        "#### Decision Tree Results:\n",
        "\n",
        "1. **Training Accuracy: 0.8042**\n",
        "   - Precision (Churn: No): 85%, Recall: 89%, F1-Score: 87%\n",
        "   - Precision (Churn: Yes): 65%, Recall: 58%, F1-Score: 61%\n",
        "\n",
        "2. **Testing Accuracy: 0.7935**\n",
        "   - Precision (Churn: No): 84%, Recall: 88%, F1-Score: 86%\n",
        "   - Precision (Churn: Yes): 62%, Recall: 55%, F1-Score: 58%\n",
        "\n",
        "#### Random Forest Results (Before SMOTE):\n",
        "\n",
        "1. **Training Accuracy: 0.8324**\n",
        "   - Precision (Churn: No): 86%, Recall: 93%, F1-Score: 89%\n",
        "   - Precision (Churn: Yes): 74%, Recall: 57%, F1-Score: 64%\n",
        "\n",
        "2. **Testing Accuracy: 0.8105**\n",
        "   - Precision (Churn: No): 84%, Recall: 92%, F1-Score: 88%\n",
        "   - Precision (Churn: Yes): 69%, Recall: 51%, F1-Score: 59%\n",
        "\n",
        "#### Random Forest Results (After SMOTE):\n",
        "\n",
        "1. **Training Accuracy: 0.8211**\n",
        "   - Precision (Churn: No): 86%, Recall: 85%, F1-Score: 86%\n",
        "   - Precision (Churn: Yes): 76%, Recall: 77%, F1-Score: 76%\n",
        "\n",
        "2. **Testing Accuracy: 0.7928**\n",
        "   - Precision (Churn: No): 87%, Recall: 84%, F1-Score: 86%\n",
        "   - Precision (Churn: Yes): 60%, Recall: 65%, F1-Score: 63%\n",
        "\n",
        "#### Top Features based on Random Forest Feature Importances:\n",
        "\n",
        "1. **Tenure (Importance: 0.177)**\n",
        "2. **Contract_Month-to-month (Importance: 0.157)**\n",
        "3. **TotalCharges (Importance: 0.128)**\n",
        "4. **MonthlyCharges (Importance: 0.096)**\n",
        "5. **InternetService_Fiber optic (Importance: 0.081)**\n",
        "\n",
        "### Overall Inference:\n",
        "\n",
        "1. **Decision Tree vs. Random Forest:**\n",
        "   - Random Forest consistently outperforms the Decision Tree in accuracy, precision, recall, and F1-score metrics.\n",
        "   - Random Forest provides more balanced predictions, especially for the minority class.\n",
        "\n",
        "2. **Impact of SMOTE on Random Forest:**\n",
        "   - Applying SMOTE improves sensitivity to predict churn in the minority class, enhancing recall and F1-score.\n",
        "   - Trade-offs in training accuracy are justifiable, considering the improved balance in predicting true positives.\n",
        "\n",
        "3. **Feature Importance:**\n",
        "   - Top features influencing churn prediction include 'Tenure,' 'Contract_Month-to-month,' 'TotalCharges,' 'MonthlyCharges,' and 'InternetService_Fiber optic.'\n",
        "   - These features offer strategic insights for customer retention, emphasizing contract types, service duration, and financial considerations.\n",
        "\n",
        "4. **Recommendations for Deployment:**\n",
        "   - The Random Forest model, especially after SMOTE, is recommended for deployment due to its enhanced predictive performance and balanced predictions.\n",
        "   - Ongoing monitoring and potential hyperparameter tuning can further optimize the model for continued effectiveness."
      ],
      "metadata": {
        "id": "8qIzEocY1MDo"
      }
    }
  ]
}